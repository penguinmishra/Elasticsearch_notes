# Document Counts-Approximate

- The counts are not accurate because of the distributed nature of the ES cluster.
- An index is distributed across multiple shards by default.
- In search, the coordinating node prompts each shard to provide top unique terms. E.g. If we search for top 3, coordinating shard asks each shard to provide top 3 terms.
- After receiving data from shards, coordinating shard computes the final result. This is where the counts may be inaccurate.
<br>

![IMG1][IMG1]

<br>

When asked by coordinating shard, each shard returns their top 3 as highlighted in above image and send the data to coordinating shard. Then the coordinating shard sorts them and what is final result by coordinating shard is in Actual Result column:

<br>

![IMG2][IMG2]

<br>
However, as we see that the correct results take into account the count of the rest of the products as well. But since shard sent their top 3, it didn't happen. B and F's counts are wrong actually.<br>
This becomes a problem when the `size` parameter is set to a lower number. But higher `size` value increases high volume of data. So, it's a trade-off between accuracy and performance. Default size though is 10.<br>
this happens because all of the documents are not on a single shard. Had it been the case, there won't have been any problem.<br>

# `doc_count_error_upper_bound`

Suppose we have the below query in which a request is made to obtain the top 5 terms in the field product, ordered by descending document count from an index with 3 shards. In this case each shard is asked to give its top 5 terms.
```
GET /_search
{
    "aggs" : {
        "products" : {
            "terms" : {
                "field" : "product",
                "size" : 5
            }
        }
    }
}
```
The terms for each of the three shards are shown below with their respective document counts in brackets:

Sr. No. | Shard A | Shard B | Shard C
--- | --- | --- | ---
1 | Product A (25) | Product A (30) | Product A (45)
2 | Product B (18) | Product B (25) | Product C (44)
3 | Product C (6) | Product F (17) | Product Z (36)
4 | Product D (3) | Product Z (16) | Product G (30)
5 | Product E (2) | Product G (15) | Product E (29)
6 | Product F (2) | Product H (14) | Product H (28)
7 | Product G (2) | Product I (10) | Product Q (2)
8 | Product H (2) | Product Q (6) | Product D (1)
9 | Product I (1) | Product J (6) | 
10 | Product J (1) | Product C (4) | 

The shards will return their top 5 terms so the results from the shards will be:

 Sr No.| Shard A | Shard B | Shard C
 --- | --- | --- | ---
 1 | Product A (25) | Product A (30) | Product A (45)
 2 | Product B (18) | Product B (25) | Product C (44)
 3 | Product C (6) | Product F (17) | Product Z (36)
 4 | Product D (3) | Product Z (16) | Product G (30)
 5 | Product E (2) | Product G (15) | Product E (29)
 
 Taking the top 5 results from each of the shards (as requested) and combining them to make a final top 5 list produces the following:


Sr No. | Products
--- | ---
1 | Product A (100)
2 | Product Z (52)
3 | Product C (50)
4 | Product G (45)
5 | product B (43)

Because Product A was returned from all shards we know that its document count value is accurate. Product C was only returned by shards A and C so its document count is shown as 50 but this is not an accurate count. Product C exists on shard B, but its count of 4 was not high enough to put Product C into the top 5 list for that shard. Product Z was also returned only by 2 shards but the third shard does not contain the term. There is no way of knowing, at the point of combining the results to produce the final list of terms, that there is an error in the document count for Product C and not for Product Z. Product H has a document count of 44 across all 3 shards but was not included in the final list of terms because it did not make it into the top five terms on any of the shards.<br><br>

## Shard Size
The higher the requested `size` is, the more accurate the results will be, but also, the more expensive it will be to compute the final results (both due to bigger priority queues that are managed on a shard level and due to bigger data transfers between the nodes and the client).
<br><br>
The `shard_size` parameter can be used to minimize the extra work that comes with bigger requested `size`. When defined, it will determine how many terms the coordinating node will request from each shard. Once all the shards responded, the coordinating node will then reduce them to a final result which will be based on the `size` parameter - this way, one can increase the accuracy of the returned terms and avoid the overhead of streaming a big list of buckets back to the client.

:white_flag: `shard_size` cannot be smaller than `size` (as it doesnâ€™t make much sense). When it is, Elasticsearch will override it and reset it to be equal to `size`.<br><br>

The default `shard_size` is `(size * 1.5 + 10).`

# Calculating Document Count Error

There are two error values which can be shown on the terms aggregation. The first gives a value for the aggregation as a whole which represents the maximum potential document count for a term which did not make it into the final list of terms. This is calculated as the sum of the document count from the last term returned from each shard. For the example given above the value would be 46 (2 + 15 + 29). This means that in the worst case scenario a term which was not returned could have the 4th highest document count.
```
{
    ...
    "aggregations" : {
        "products" : {
            "doc_count_error_upper_bound" : 46,
            "sum_other_doc_count" : 79,
            "buckets" : [
                {
                    "key" : "Product A",
                    "doc_count" : 100
                },
                {
                    "key" : "Product Z",
                    "doc_count" : 52
                }
                ...
            ]
        }
    }
}
```

# Per Bucket Document Count Error
The second error value can be enabled by setting the `show_term_doc_count_error` parameter to true:
```
GET /_search
{
    "aggs" : {
        "products" : {
            "terms" : {
                "field" : "product",
                "size" : 5,
                "show_term_doc_count_error": true
            }
        }
    }
}
```
This shows an error value for each term returned by the aggregation which represents the *worst* case error in the document count and can be useful when deciding on a value for the `shard_size` parameter. This is calculated by summing the document counts for the last term returned by all shards which did not return the term. In the example above the error in the document count for Product C would be 15 as Shard B was the only shard not to return the term and the document count of the last term it did return was 15. The actual document count of Product C was 54 so the document count was only actually off by 4 even though the worst case was that it would be off by 15. Product A, however has an error of 0 for its document count, since every shard returned it we can be confident that the count returned is accurate.

```
{
    ...
    "aggregations" : {
        "products" : {
            "doc_count_error_upper_bound" : 46,
            "sum_other_doc_count" : 79,
            "buckets" : [
                {
                    "key" : "Product A",
                    "doc_count" : 100,
                    "doc_count_error_upper_bound" : 0
                },
                {
                    "key" : "Product Z",
                    "doc_count" : 52,
                    "doc_count_error_upper_bound" : 2
                }
                ...
            ]
        }
    }
}
```
These errors can only be calculated in this way when the terms are ordered by descending document count. When the aggregation is ordered by the terms values themselves (either ascending or descending) there is no error in the document count since if a shard does not return a particular term which appears in the results from another shard, it must not have that term in its index. When the aggregation is either sorted by a sub aggregation or in order of ascending document count, the error in the document counts cannot be determined and is given a value of -1 to indicate this.