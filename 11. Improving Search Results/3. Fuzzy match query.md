# Fuzzy match query
*Handling Typos*

- example: searching for lobster but user typed l0bster.

![IMG1][IMG1]

<br>

![IMG2][IMG2]

- This is handled by fuziness by adding a parameter named `fuziness` in the `match_query`.
- If we type lobster correctly, we have the below `match` query.
```
GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "lobster"
      }
    }
  }
}
```
 but suppose we hit 0 instead of o, then:
 ```
 GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "l0bster"
      }
    }
  }
}
 ```
 Does not give any results which the user didn't want to happen. The intention was to search for the term lobster. We can fix that by adding a paramter named `fuziness`:
 ```
 GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "l0bster",
        "fuzziness": "auto"
      }
    }
  }
}
```
- For now, let's stay with the value of `fuziness` as `auto`. Now with the above query, we get the results.
- Fuziness is implemented by calculating Levenstein distance which is commonly referred to as edit distance.
- Edit distance between them is the minumum number of single character edits that are needed to change one of the words into the other. Single character edit can be an instertion, deletion or substitution.
- Changing lobster to l0bster requires only one substitution- 0 with o. So the edit distance in our example is 1.
- A different algorithm is used for calculating fuziness (with `slop`) in the `match_phrase` query.
- So you cannot compare `slop` with `fuziness` as parameters since the edit distances are calculated differently. With the Levenstein distance we are not moving characters around as we were with the `match_phrase` query.
- `auto` tells ES to handle fuziness automatically for us. This ES does by looking at each terms and uses the following rules:

![IMG3][IMG3]

- A maximum edit distance that can ve ysed is 2. The reasons behind this are:
	- Studies have shown that 80% of human misspellings can be corrected with an edit distance of just 1. So 1 or 2 will catch almost all the mistakes.
	- High fuziness value would quickly reduce performance.
	- Also, a higher fuziness value would mean that you would begin to see strange and unpredictable results.
- That is why leaving the value at `auto` is generally a good idea because quickly you would find yourself writing a similar algorithm determinng appropriate value based on the input length to avoid strange matches.
- If we search for lobster with `fuziness` parameter set, then we would get some other matches such as oyster:
```
GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "lobster",
        "fuzziness": "auto"
      }
    }
  }
}
```
gives:
```
[TRUNCATED]
{
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "610",
        "_score" : 4.0467296,
        "_source" : {
          "name" : "Sauce - Oyster",
          "price" : 99,
          "in_stock" : 11,
          "sold" : 31,
[TRUNCATED]
```

- This happened because it took 2 edit distance to reach from lobster to oyster - removal of leading l. and then replacing b with a y.
- Fuziness is per term basis. Let's mention two terms and see that:
```
GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "l0bster love",
        "operator": "and", 
        "fuzziness": 1
      }
    }
  }
}
```
Which gives:
```
[TRUNCATED]
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "19",
        "_score" : 10.113076,
        "_source" : {
          "name" : "Lobster - Live",
[TRUNCATED]
```

- We still get results with lobster and live. which proves that the fuziness is per term basis. In here a total of 2 edit distances were required.
- Levenstein algorithm was extended with a so-called transpositions which means swapping of two adjacent characters:

![IMG4][IMG4]

- One transposition is counted as one edit distance. Let's see an example:
```
GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "lvie", 
        "fuzziness": 1
      }
    }
  }
}
```
This gives:
```
[TRUNCATED]
{
        "_index" : "products",
        "_type" : "_doc",
        "_id" : "19",
        "_score" : 5.113107,
        "_source" : {
          "name" : "Lobster - Live",
[TRUNCATED]
```
- lvie to live was only one transposition which happened in a single edit distance and the query matches it with live. Otherwise there is no way to accommodate 1 transposition in a single edit distance.
- Transpositions are enabled by default.
- We can disable transpositions by setting `fuzzy_transpositions` parameter to false:
```
GET /products/_search
{
  "query": {
    "match": {
      "name": {
        "query": "lvie", 
        "fuzziness": 1,
        "fuzzy_transpositions": false
      }
    }
  }
}
```
And this query does not give any results.

[IMG1]: <https://github.com/penguinmishra/images_repo/blob/master/Elasticsearch/typo_fuzzy.JPG>
[IMG2]: <https://github.com/penguinmishra/images_repo/blob/master/Elasticsearch/typo_fuzzy_2.JPG>
[IMG3]: <https://github.com/penguinmishra/images_repo/blob/master/Elasticsearch/fuziness_rules.JPG>
[IMG4]: <https://github.com/penguinmishra/images_repo/blob/master/Elasticsearch/transposition.JPG>